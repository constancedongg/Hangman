{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hangman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game rule:\n",
    "\n",
    "When a player plays Hangman, the program randomly selects a secrete word from the word dictionary. Each time, the player guess a letter, if the letter is in the secrete word, the system will return the location of that letter; if it is not, the player lose one chance. In total, the player gets 6 chances of incorrect guesses. In the end, the player either win the game by guessing the word within 6 incorrect guesses or lose.\n",
    "\n",
    "\n",
    "The dictionary contains 370099 words in total. The success rate is roughly 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy:\n",
    "\n",
    "#### Abstract: \n",
    "Basic idea is to mimic the n-gram model in text mining, but here instead of paritioning sentence into words, I partition the word into n contiguous letters. Then I partition the word to guess in the same way and match the n-gram model. Finally use simple Bayesian probability to decide which letter to guess next. The algorithm gets 50% success rate for 6 chances.\n",
    "\n",
    "#### Step 1:\n",
    "For the word in given dictionary, we partition each word into bigram, trigram, fourgram and fivegram. For example, for the word 'apple' of bigram model, the word is partitioned into 'ap', 'pp', 'pl', 'le'. For the given training data, we loop over all the word and four n-gram models, and save the frequency distributions of 4 n-gram models into dictionary. So the dictionary of bigram looks like {'aa': 100, 'ab':100,... ,'zz':0}, etc.\n",
    "This step is set aside the class Hangman API to avoid repetitive calculation of frequency. Once built, values can be directly used according to keys.\n",
    "\n",
    "#### Step 2:\n",
    "For the first guess when the word given is composed of all underlines like this '_ _ _ _ _'. We guess it according to the frequency of alphabets of words with the matched length. For example, the given word is like the above one, we first find all words of length 5 in the training data, then calculate the frequency of each alphabet for all these matched word. Then we make the first guess on the letter which has the highest frequency, which is typically vowels like 'e', 'i', etc. But for words of different lengths, the first guess still varies.\n",
    "\n",
    "#### Step 3:\n",
    "Once, we make the first right guess. We get the word like '_ e _ _ _'. Then we try to get more information based on the given information, i.e., the given 'e'. To maximize P(letter_i | 'e'), by Bayesian, we need to maximize P(letter_i ,'e'), so I search the dictionary of bigram model, retrieve all keys match regular expression of '.e' and 'e.', and save the corresponding values of that key to the letter_i. For example, if 'le' has frequency 12000 and 'el' has frequency 5000, then we frequency of letter l is 12000 + 5000 = 17000. Then for each alphabet a-z, we calculate the frequency, and make the guess on the one with the highest frequency.\n",
    "\n",
    "\n",
    "Then for 'l e _ _ _', we apply trigram model because it contains the pattern 'le_', which is to maximize P(letter_i | 'le'). We search keys in trigram dictionary which matches the pattern 'le.', and save the frequency of matched last letter. For trigram model, we only consider 3 scenerios, i.e., 'ab_', 'a_b', '_ab', which is two letters within 3 are known and one is blank. For fourgram, we also consider the pattern with only one blank, which are '_abc' , 'a_bc' , 'ab_c' , 'abc_'. For fivegram model, we still consider only one blank, which are '_abcd', 'a_bcd', 'ab_cd' , 'abc_d', 'abcd_'.\n",
    "\n",
    "#### Step 4:\n",
    "Final decision rule is that once the given word matches fivegram pattern, which is it only contains one blank for length of 5, we decide simply by frequency given by fivegram model; if no, try the fourgram, then trigram, finally bigram. \n",
    "\n",
    "\n",
    "Reason: 1. Magnitude of frequency of different grams are different. For bigram, we may get 20000 for 'in' but for fivegram like 'inter' we may get only like 500, for others maybe fewer. But we can still combine all gram models together by using final_frequency = c1 * bigram_freq + c2 * trigram_freq + c3 * fourgram_freq + c4 * fivegram_freq, and then tune coefficients.\n",
    "2. Higher gram means more information given. It is more reasonable to guess 'r' by using 'inte_' than guessing 'r' by simply using 'e_'.\n",
    "\n",
    "\n",
    "\n",
    "#### Assumption:\n",
    "1. Distributions of alphabets frequency for words in training data are the same as those in the test data. It means, for example, for bigram frequency distribution {'aa': 100, 'ab':100,... 'zz':0}, the distributions are roughly the same.\n",
    "2. Higher gram models contain more information than lower grams.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary_location = \"words_dict.txt\"\n",
    "text_file = open(dictionary_location,\"r\")\n",
    "full_dictionary = text_file.read().splitlines()\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370099"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'aa', 'aaa', 'aah', 'aahed']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dictionary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# form bigram, trigram, four_gram, five_gram frequency distribution for all words in training\n",
    "\n",
    "def grams_freq(dictionary):\n",
    "    freq_2 = {}\n",
    "    freq_3 = {}\n",
    "    freq_4 = {}\n",
    "    freq_5 = {}\n",
    "\n",
    "    for word in dictionary:\n",
    "        if len(word) >= 2:\n",
    "            for i in range(len(word) - 1):\n",
    "                tmp = word[i : (i + 2)]\n",
    "                if tmp not in freq_2:\n",
    "                    freq_2[tmp] = 1\n",
    "                else:\n",
    "                    freq_2[tmp] += 1\n",
    "        if len(word) >= 3:\n",
    "            for i in range(len(word) - 2):\n",
    "                tmp = word[i : (i + 3)]\n",
    "                if tmp not in freq_3:\n",
    "                    freq_3[tmp] = 1\n",
    "                else:\n",
    "                    freq_3[tmp] += 1\n",
    "        if len(word) >= 4:\n",
    "            for i in range(len(word) - 3):\n",
    "                tmp = word[i : (i + 4)]\n",
    "                if tmp not in freq_4:\n",
    "                    freq_4[tmp] = 1\n",
    "                else:\n",
    "                    freq_4[tmp] += 1\n",
    "        if len(word) >= 5:\n",
    "            for i in range(len(word) - 4):\n",
    "                tmp = word[i : (i + 5)]\n",
    "                if tmp not in freq_5:\n",
    "                    freq_5[tmp] = 1\n",
    "                else:\n",
    "                    freq_5[tmp] += 1\n",
    "    return freq_2 , freq_3 , freq_4 , freq_5\n",
    "\n",
    "freq_2 , freq_3 , freq_4 , freq_5 = grams_freq(full_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa': 255, 'ah': 1449, 'ed': 30877, 'he': 18798, 'hi': 14800}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(freq_2.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aahed': 1, 'aahin': 1, 'aalii': 2, 'ahing': 4, 'aliis': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(freq_5.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unigram(dictionary , current_word):\n",
    "    len_word = len(current_word)\n",
    "    new_dictionary = []\n",
    "    for word in dictionary:\n",
    "        if len(word) == len_word:\n",
    "            new_dictionary.append(word)\n",
    "\n",
    "    # initialize the unigram alphabet frequency dictionary with 0 for each character\n",
    "    unigram_freq = dict.fromkeys(string.ascii_lowercase, 0)\n",
    "    for word in new_dictionary:\n",
    "        # count each distinct charater once for each word, that is, duplicate characters are counted once in each word\n",
    "        for char in list(set(word)):\n",
    "            unigram_freq[char] += 1   \n",
    "    return unigram_freq\n",
    "\n",
    "\n",
    "tmp_d = unigram(full_dictionary , '____')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2704,\n",
       " 'b': 772,\n",
       " 'c': 823,\n",
       " 'd': 1051,\n",
       " 'e': 2346,\n",
       " 'f': 512,\n",
       " 'g': 773,\n",
       " 'h': 812,\n",
       " 'i': 1709,\n",
       " 'j': 209,\n",
       " 'k': 777,\n",
       " 'l': 1397,\n",
       " 'm': 903,\n",
       " 'n': 1301,\n",
       " 'o': 1933,\n",
       " 'p': 911,\n",
       " 'q': 51,\n",
       " 'r': 1550,\n",
       " 's': 1868,\n",
       " 't': 1386,\n",
       " 'u': 1238,\n",
       " 'v': 302,\n",
       " 'w': 563,\n",
       " 'x': 161,\n",
       " 'y': 766,\n",
       " 'z': 180}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Hangman(object):\n",
    "    def __init__(self):\n",
    "        self.guessed_letters = []\n",
    "\n",
    "    ## unigram model may only be used once for the first guess till correct, because for afterward guess, unigram model\n",
    "    ## character frequency may shift others frequency like bigram, trigram a lot. \n",
    "\n",
    "    # dictionary is the training data, and current_word is the current word to guess like 'a__le' (without stripes).\n",
    "    def unigram(self, dictionary , current_word):\n",
    "        len_word = len(current_word)\n",
    "        new_dictionary = []\n",
    "        for word in dictionary:\n",
    "            if len(word) == len_word:\n",
    "                new_dictionary.append(word)\n",
    "            \n",
    "        # initialize the unigram alphabet frequency dictionary with 0 for each character\n",
    "        unigram_freq = dict.fromkeys(string.ascii_lowercase, 0)\n",
    "        for word in new_dictionary:\n",
    "            # count each distinct charater once for each word, that is, duplicate characters are counted once in each word\n",
    "            for char in list(set(word)):\n",
    "                unigram_freq[char] += 1   \n",
    "        return unigram_freq\n",
    "              \n",
    "\n",
    "    \n",
    "    # Consider only 2 scenerios for bigram model, '_a' and 'a_' , that is, to form the bigram frequency table for unknown\n",
    "    # characters next to know characters, suppose there is some known character for current word\n",
    "    # Suppose for bigram model, there is no difference for frequency distribution of different lengths of word\n",
    "    def bigram(self, freq_2 , current_word):\n",
    "        bigram_freq = dict.fromkeys(string.ascii_letters, 0)\n",
    "        \n",
    "        if len(current_word) >= 2:\n",
    "            for i in range(len(current_word) - 1):\n",
    "                bigram_tmp = current_word[i : (i + 2)]\n",
    "\n",
    "                # pattern '_a'\n",
    "                if re.match('_.',bigram_tmp) and bigram_tmp != '__':\n",
    "                    pattern = '.' + bigram_tmp[1]\n",
    "                    for key in freq_2.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            bigram_freq[key[0]] += freq_2[key]\n",
    "                # pattern 'a_'\n",
    "                elif re.match('._' , bigram_tmp) and bigram_tmp != '__':\n",
    "                    pattern = bigram_tmp[0] + '.' \n",
    "                    for key in freq_2.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            bigram_freq[key[1]] += freq_2[key]\n",
    "        return bigram_freq\n",
    "\n",
    "\n",
    "\n",
    "    def trigram(self , freq_3 , current_word):\n",
    "        trigram_freq = dict.fromkeys(string.ascii_letters, 0)\n",
    "        \n",
    "        if len(current_word) >= 3:\n",
    "            for i in range(len(current_word) - 2):\n",
    "                trigram_tmp = current_word[i : (i + 3)]\n",
    "                \n",
    "                # for pattern '_ab', record the alphabet frequency for the first character\n",
    "                if re.match('_[a-z]{2}',trigram_tmp):\n",
    "                    pattern = '.' + trigram_tmp[1 : 2]\n",
    "                    for key in freq_3.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            trigram_freq[key[0]] += freq_3[key]\n",
    "\n",
    "                # for pattern 'a_b'\n",
    "                elif re.match('[a-z]_[a-z]' , trigram_tmp):\n",
    "                    pattern = trigram_tmp[0] + '.' + trigram_tmp[2]\n",
    "                    for key in freq_3.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            trigram_freq[key[1]] += freq_3[key]\n",
    "\n",
    "                # for pattern 'ab_'\n",
    "                elif re.match('[a-z]{2}_' , trigram_tmp):\n",
    "                    pattern = trigram_tmp[0 : 2] + '.' \n",
    "                    for key in freq_3.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            trigram_freq[key[2]] += freq_3[key]\n",
    "                            \n",
    "        return trigram_freq\n",
    "    \n",
    "\n",
    "\n",
    "    def fourgram(self , freq_4 , current_word):\n",
    "        fourgram_freq = dict.fromkeys(string.ascii_letters, 0)\n",
    "        \n",
    "        if len(current_word) >= 4:\n",
    "            for i in range(len(current_word) - 3):\n",
    "                fourgram_tmp = current_word[i : (i + 4)]\n",
    "\n",
    "                # pattern '_abc'\n",
    "                if re.match('_[a-z]{3}',fourgram_tmp):\n",
    "                    pattern = '.' + fourgram_tmp[1 : 4]\n",
    "                    for key in freq_4.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fourgram_freq[key[0]] += freq_4[key]\n",
    "\n",
    "                # pattern 'a_bc'           \n",
    "                elif re.match('[a-z]_[a-z]{2}' , fourgram_tmp):\n",
    "                    pattern = fourgram_tmp[0] + '.' + fourgram_tmp[2 : 4] \n",
    "                    for key in freq_4.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fourgram_freq[key[1]] += freq_4[key]\n",
    "                \n",
    "                # pattern 'ab_c'\n",
    "                elif re.match('[a-z]{2}_[a-z]' , fourgram_tmp):\n",
    "                    pattern = fourgram_tmp[0 : 2] + '.' + fourgram_tmp[3]\n",
    "                    for key in freq_4.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fourgram_freq[key[2]] += freq_4[key]\n",
    "                \n",
    "                # pattern 'abc_'\n",
    "                elif re.match('[a-z]{3}_' , fourgram_tmp):\n",
    "                    pattern = fourgram_tmp[0 : 3] + '.' \n",
    "                    for key in freq_4.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fourgram_freq[key[3]] += freq_4[key]\n",
    "                             \n",
    "        return fourgram_freq\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def fivegram(self, freq_5 , current_word):\n",
    "        fivegram_freq = dict.fromkeys(string.ascii_letters, 0)\n",
    "\n",
    "        if len(current_word) >=5 :\n",
    "            for i in range(len(current_word) - 4):\n",
    "                fivegram_tmp = current_word[i : (i + 5)]\n",
    "\n",
    "                # pattern '_abcd'\n",
    "                if re.match('_[a-z]{4}' , fivegram_tmp):\n",
    "                    pattern = '.' + fivegram_tmp[1 : 5]\n",
    "                    for key in freq_5.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fivegram_freq[key[0]] += freq_5[key]\n",
    "\n",
    "                # pattern 'a_bcd'\n",
    "                elif re.match('[a-z]_[a-z]{3}' , fivegram_tmp):\n",
    "                    pattern = fivegram_tmp[0] + '.' + fivegram_tmp[2 : 5]\n",
    "                    for key in freq_5.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fivegram_freq[key[1]] += freq_5[key]\n",
    "                \n",
    "                # pattern 'ab_cd'\n",
    "                elif re.match('[a-z]{2}_[a-z]{2}' , fivegram_tmp):\n",
    "                    pattern = fivegram_tmp[0 : 2] + '.' + fivegram_tmp[3 : 5]\n",
    "                    for key in freq_5.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fivegram_freq[key[2]] += freq_5[key]\n",
    "\n",
    "                # pattern 'abc_d'\n",
    "                elif re.match('[a-z]{3}_[a-z]' , fivegram_tmp):\n",
    "                    pattern = fivegram_tmp[0 : 3] + '.' + fivegram_tmp[4]\n",
    "                    for key in freq_5.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fivegram_freq[key[3]] += freq_5[key]\n",
    "                 \n",
    "                # pattern 'abcd_'\n",
    "                elif re.match('[a-z]{4}_' , fivegram_tmp):\n",
    "                    pattern = fivegram_tmp[0 : 4] + '.' \n",
    "                    for key in freq_5.keys():\n",
    "                        if re.match(pattern , key):\n",
    "                            fivegram_freq[key[4]] += freq_5[key]\n",
    "                \n",
    "        \n",
    "        return fivegram_freq\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "    def guess(self, word): # word input example: \"_ p p _ e \"\n",
    "        \n",
    "        # clean the word so that we strip away the space characters\n",
    "        clean_word = word[::2]\n",
    "        len_word = len(clean_word)\n",
    "    \n",
    "        # for the first guess when all are blank\n",
    "        if clean_word == '_' * len_word:\n",
    "            self.freq_f = self.unigram(full_dictionary , clean_word)\n",
    "\n",
    "        else:\n",
    "            self.freq_f  = dict.fromkeys(string.ascii_letters, 0)\n",
    "            bigram_freq = self.bigram(freq_2 , clean_word)\n",
    "            trigram_freq = self.trigram(freq_3 , clean_word)\n",
    "            fourgram_freq = self.fourgram(freq_4 , clean_word)\n",
    "            fivegram_freq = self.fivegram(freq_5 , clean_word)\n",
    "\n",
    "            if any(value != 0 for value in fivegram_freq.values()):\n",
    "                for key in self.freq_f.keys():\n",
    "                    self.freq_f[key] = fivegram_freq[key]\n",
    "            elif any(value != 0 for value in fourgram_freq.values()):\n",
    "                for key in self.freq_f.keys():\n",
    "                    self.freq_f[key] = fourgram_freq[key]\n",
    "            elif any(value != 0 for value in trigram_freq.values()):\n",
    "                for key in self.freq_f.keys():\n",
    "                    self.freq_f[key] = trigram_freq[key]\n",
    "            else:\n",
    "                for key in self.freq_f.keys():\n",
    "                    self.freq_f[key] = bigram_freq[key]\n",
    "\n",
    "        \n",
    "\n",
    "        # sort the keys of self.freq_f in descending order\n",
    "        sorted_letter_count = sorted(self.freq_f, key = self.freq_f.get, reverse = True)    \n",
    "\n",
    "        # pick the letter with largest frequency and meanwhile not be guessed before\n",
    "        for letter in sorted_letter_count:\n",
    "            if letter not in self.guessed_letters:\n",
    "                guess_letter = letter\n",
    "                break\n",
    "\n",
    "        \n",
    "        return guess_letter\n",
    "        \n",
    "        \n",
    "    \n",
    "    def start_game(self):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = []\n",
    "        output = False\n",
    "        \n",
    "        # randomly select a word to guess from the full dictionary\n",
    "        word = random.choice(full_dictionary)\n",
    "        return_word = \"_ \" * len(word)\n",
    "        \n",
    "        \n",
    "        tries_remains = 6\n",
    "        print('New game start! No. of tries remains:', tries_remains , '. Word to guess is:' , return_word , '.\\n')\n",
    "        \n",
    "        while tries_remains > 0 :            \n",
    "            guess_letter = self.guess(return_word)\n",
    "        \n",
    "            self.guessed_letters.append(guess_letter)\n",
    "            \n",
    "            print('Guessing letter is: ' + guess_letter)\n",
    "            \n",
    "            if guess_letter in word:\n",
    "                ind = [i for i, a in enumerate(word) if a == guess_letter]\n",
    "                for i in ind:\n",
    "                    return_word = return_word[ : 2 * i] + guess_letter + return_word[(2 * i + 1) : ]\n",
    "                    \n",
    "                if '_' not in return_word:\n",
    "                    print('SUCCESS!! The word is: ' + word, '\\n')\n",
    "                    output = True\n",
    "                    break\n",
    "                else:\n",
    "                    print('Correct!', 'Now the word is: ' + return_word + '. No. of tries remains:' , tries_remains, '. \\n')\n",
    "            else:\n",
    "                tries_remains -= 1\n",
    "                print('Wrong!' , 'The word is still:' + return_word +'. No. of tries remains:' , tries_remains, '. \\n')\n",
    "            \n",
    "            \n",
    "        if '_' in return_word:\n",
    "            print('You lose the game :( The word to guess is: ' + word)\n",
    "             \n",
    "        return output        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New game start! No. of tries remains: 6 . Word to guess is: _ _ _ _ _ _ _ _ _ _ _  .\n",
      "\n",
      "Guessing letter is: e\n",
      "Correct! Now the word is: _ e _ _ _ _ _ _ _ _ _ . No. of tries remains: 6 . \n",
      "\n",
      "Guessing letter is: r\n",
      "Correct! Now the word is: _ e _ r _ _ _ _ _ _ _ . No. of tries remains: 6 . \n",
      "\n",
      "Guessing letter is: t\n",
      "Wrong! The word is still:_ e _ r _ _ _ _ _ _ _ . No. of tries remains: 5 . \n",
      "\n",
      "Guessing letter is: a\n",
      "Wrong! The word is still:_ e _ r _ _ _ _ _ _ _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: u\n",
      "Correct! Now the word is: _ e u r _ _ _ _ _ _ _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: n\n",
      "Correct! Now the word is: n e u r _ _ _ _ _ _ _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: o\n",
      "Correct! Now the word is: n e u r o _ _ _ _ _ _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: p\n",
      "Correct! Now the word is: n e u r o p _ _ _ _ _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: h\n",
      "Correct! Now the word is: n e u r o p h _ _ _ _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: i\n",
      "Correct! Now the word is: n e u r o p h i _ i _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: l\n",
      "Correct! Now the word is: n e u r o p h i l i _ . No. of tries remains: 4 . \n",
      "\n",
      "Guessing letter is: s\n",
      "Wrong! The word is still:n e u r o p h i l i _ . No. of tries remains: 3 . \n",
      "\n",
      "Guessing letter is: c\n",
      "SUCCESS!! The word is: neurophilic \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = Hangman().start_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To hide the print of process of the game\n",
    "import os, sys\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def success_rate(n , print_process = False):\n",
    "    success = 0\n",
    "    for i in range(n):\n",
    "        if print_process == False:\n",
    "            # hide print\n",
    "            with HiddenPrints():       \n",
    "                success += Hangman().start_game()\n",
    "        else:\n",
    "            # print the guessing process of each game\n",
    "            success += Hangman().start_game()\n",
    "            \n",
    "    print('By playing {} games, the success rate is {:.2f}'.format(n , success / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By playing 100 games, the success rate is 0.54\n"
     ]
    }
   ],
   "source": [
    "success_rate(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
